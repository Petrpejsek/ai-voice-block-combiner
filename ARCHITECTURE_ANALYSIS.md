# üìê ARCHITECTURE ANALYSIS - Complete Flow, Contracts & Integration Points

**C√≠l:** Kompletn√≠ soupis architektury pro n√°vrh perfektn√≠ architektury s 2 AI asistenty (Query Director + Curator) a source packem.

**Datum:** 2025-01-05  
**Analyzov√°no:** 100% souƒçasn√© codebase

---

## üîç 1) SOUƒåASN√ù END-TO-END FLOW

### **Pipeline Overview**

Pipeline m√° 8 hlavn√≠ch krok≈Ø od t√©matu po fin√°ln√≠ video:

```
USER INPUT (topic)
   ‚Üì
1. RESEARCH ASSISTANT (LLM) ‚Üí research.json
   ‚Üì
2. NARRATIVE ASSISTANT (LLM) ‚Üí draft_script.json
   ‚Üì
3. VALIDATOR ASSISTANT (LLM) ‚Üí validation_result.json
   ‚Üì
4. COMPOSER (deterministic) ‚Üí tts_ready_package.json
   ‚Üì
5. VOICEOVER GENERATION (ElevenLabs TTS) ‚Üí *.mp3 files
   ‚Üì
6. FOOTAGE DIRECTOR (FDA - LLM) ‚Üí shot_plan.json
   ‚Üì
7. ARCHIVE ASSET RESOLVER (AAR - search) ‚Üí archive_manifest.json
   ‚Üì
8. COMPILATION BUILDER (CB - FFmpeg) ‚Üí final.mp4
```

---

### **KROK 1: RESEARCH ASSISTANT** ‚ö° **TADY VZNIK√Å T√âMA**

**Soubor:** `backend/script_pipeline.py`  
**Funkce:** `_step_research()`  
**Volaj√≠c√≠:** `/api/script/generate` endpoint v `app.py`

**Flow:**
```
INPUT: 
  - topic (string, user input)
  - language (string)
  - target_minutes (int)
  - channel_profile (string)

TRANSFORMACE:
  1. Sestav√≠ prompt pro Research Assistant (LLM)
  2. Vol√° LLM (OpenAI/OpenRouter) s promptem
  3. Parse JSON response
  4. Validace struktury

OUTPUT (research_report.json):
  {
    "topic": "Napoleon in Moscow: The 1812 Occupation",
    "language": "en",
    "timeline": [{"period": "1812", "event": "..."}],
    "claims": [{"claim_id": "c_001", "text": "...", "importance": "high"}],
    "entities": [{"name": "Napoleon", "type": "person"}],
    "open_questions": ["..."]
  }

ULO≈ΩEN√ç: projects/<episode_id>/script_state.json ‚Üí metadata.research_report
```

**Kde se ukl√°d√°:**
- Prim√°rnƒõ: `script_state.json` (persistent state)
- Format: JSON object v `metadata.research_report`

**‚ùå PROBL√âM:** 
- ≈Ω√°dn√° kontrola "coverage" (mapy/lidi/dokumenty/m√≠sta nejsou systematicky mapov√°ny)
- Entities jsou jen seznam, nen√≠ typologie (geography, artifacts, events)

---

### **KROK 2: NARRATIVE ASSISTANT**

**Soubor:** `backend/script_pipeline.py`  
**Funkce:** `_step_narrative()`  
**Volaj√≠c√≠:** Script pipeline (n√°sleduje po Research)

**Flow:**
```
INPUT:
  - research_report (z kroku 1)
  - channel_profile
  - patch_instructions (optional)

TRANSFORMACE:
  1. Sestav√≠ prompt s research_report + creative guidelines
  2. Vol√° LLM pro narrative structuring
  3. Parse JSON response
  4. Validace chapter/block structure

OUTPUT (draft_script.json):
  {
    "title_candidates": ["..."],
    "hook": "In 1812...",
    "chapters": [
      {
        "chapter_id": "ch_01",
        "title": "Aims of the Invasion",
        "narration_blocks": [
          {
            "block_id": "b_0001",
            "text": "In eighteen twelve, Napoleon led...",
            "claim_ids": ["c_001"]
          }
        ]
      }
    ]
  }

ULO≈ΩEN√ç: script_state.json ‚Üí metadata.draft_script
```

**‚ùå PROBL√âM:**
- ≈Ω√°dn√Ω explicitn√≠ "visual intent" per block/chapter
- Nen√≠ guidance pro AAR (co pot≈ôebujeme vizu√°lnƒõ)

---

### **KROK 3: VALIDATOR ASSISTANT**

**Soubor:** `backend/script_pipeline.py`  
**Funkce:** `_step_validation()`

**Flow:**
```
INPUT:
  - research_report
  - draft_script

TRANSFORMACE:
  1. Cross-check fact claims vs narrative
  2. Validace claim_ids integrity
  3. LLM verification of accuracy

OUTPUT (validation_result.json):
  {
    "status": "PASS" | "FAIL",
    "issues": [...],
    "approved_script": {...}
  }

ULO≈ΩEN√ç: script_state.json ‚Üí metadata.validation_result
```

---

### **KROK 4: COMPOSER (DETERMINISTIC)**

**Soubor:** `backend/script_pipeline.py`  
**Funkce:** `_deterministic_compose()`

**Flow:**
```
INPUT:
  - research_report
  - draft_script
  - validation_result

TRANSFORMACE (PURE DETERMINISTIC, NO LLM):
  1. Merge validated script into final structure
  2. Flatten narration_blocks across chapters
  3. Add TTS guidelines
  4. Title selection (deterministic)

OUTPUT (tts_ready_package.json):
  {
    "episode_id": "ep_024286848837",
    "language": "en",
    "selected_title": "Napoleon in Moscow: The 1812 Occupation",
    "chapters": [...],
    "narration_blocks": [
      {
        "block_id": "b_0001",
        "claim_ids": ["c_001"],
        "text_tts": "In eighteen twelve, Napoleon led..."
      }
    ],
    "tts_guidelines": {
      "voice_style": "documentary_narrator",
      "pace_wpm_hint": 160
    }
  }

ULO≈ΩEN√ç: script_state.json ‚Üí metadata.tts_ready_package
```

---

### **KROK 5: VOICEOVER GENERATION (TTS)**

**Soubor:** `backend/app.py`  
**Endpoint:** `/api/generate-voiceover/<episode_id>`  
**Funkce:** Integrace s ElevenLabs nebo Google TTS

**Flow:**
```
INPUT:
  - tts_ready_package (z kroku 4)
  - ElevenLabs API key

TRANSFORMACE:
  1. Extract narration_blocks[] z package
  2. Pro ka≈æd√Ω block:
     - Vol√° ElevenLabs TTS API s text_tts
     - Z√≠sk√° audio (MP3 base64)
     - Save to projects/<episode_id>/voiceover/<block_id>.mp3
  3. Pause insertion mezi bloky (600ms default)

OUTPUT:
  - MP3 soubory v projects/<episode_id>/voiceover/
  - Metadata o vygenerovan√Ωch souborech

ULO≈ΩEN√ç: 
  - Fyzick√© MP3: projects/<episode_id>/voiceover/Narrator_0001.mp3
  - Metadata: script_state.json ‚Üí voiceover_status
```

**‚ùå PROBL√âM:**
- TTS generace je izolovan√° od vizu√°ln√≠ planning - nen√≠ synchronizace

---

### **KROK 6: FOOTAGE DIRECTOR (FDA)** ‚ö° **TADY VZNIKAJ√ç QUERIES**

**Soubor:** `backend/footage_director.py`  
**Funkce:** `run_fda_llm()`  
**Volaj√≠c√≠:** `/api/video/footage-director-llm/<episode_id>` endpoint

**Flow:**
```
INPUT:
  - tts_ready_package (obsahuje narration_blocks[])
  - episode_id

TRANSFORMACE:
  1. Extract narration_blocks
  2. Sestav√≠ mega-prompt pro LLM (GPT-4o-mini):
     - Po≈æaduje scene-by-scene shot planning
     - Shot types (enum): historical_battle_footage, maps_context, archival_documents, etc.
  3. LLM vr√°t√≠ ScenePlan v3 (kreativn√≠ JSON)
  4. DETERMINISTICK√Å KOMPILACE do ShotPlan v3:
     - visual_planning_v3.py ‚Üí compile_scene_plan_to_shot_plan()
     - Generuje search_queries[] deterministicky z narration + entities
     - Generuje keywords[] z narration text

OUTPUT (shot_plan.json):
  {
    "version": "fda_v2.7",
    "episode_topic": "Napoleon in Moscow",
    "scenes": [
      {
        "scene_id": "s_0001",
        "block_id": "b_0001",
        "narration_summary": "Napoleon led Grande Arm√©e into Russia.",
        "narration_summary_original": "...",
        "emotion": "neutral",
        "cut_rhythm": "slow",
        "duration_seconds": 18.5,
        "keywords": ["Napoleon", "Grande Arm√©e", "1812", "Russia"],
        "search_queries": [
          {
            "query": "Napoleon 1812 archival map public domain",
            "reasoning": "Geographic context"
          },
          {
            "query": "Grande Arm√©e historical engraving public domain",
            "reasoning": "Troop movement"
          }
        ],
        "shots": [
          {
            "shot_id": "shot_0001",
            "shot_type": "maps_context",
            "duration_seconds": 8.0,
            "keywords": ["Napoleon", "Russia", "1812"],
            "search_queries": ["Napoleon 1812 Russia map archival"]
          }
        ]
      }
    ]
  }

ULO≈ΩEN√ç: script_state.json ‚Üí metadata.shot_plan
```

**‚ùó KDE SE GENERUJ√ç QUERIES:**

1. **LLM f√°ze (footage_director.py):**
   - Prompt v `_prompt_footage_director()` (≈ô√°dek ~2232)
   - LLM dost√°v√° narration_blocks a mus√≠ vr√°tit scenes[] s search_queries
   - Format: `{"query": "...", "reasoning": "..."}`

2. **Deterministick√° kompilace (visual_planning_v3.py):**
   - Funkce `_queries_for_scene()` (≈ô√°dek 454-513)
   - Generuje queries z:
     - `_scene_anchor_tokens()` ‚Üí extrahuje entity/year z narration
     - Shot types ‚Üí ovliv≈àuje priority (maps_context ‚Üí map queries first)
     - Base object templates: `["archival", "map"]`, `["historical", "engraving"]`, atd.
   - Garantovan√Ω output: **5 queries per scene**

3. **Query Guardrails (query_guardrails.py):**
   - Funkce `validate_and_fix_queries()` je vol√°na v `visual_planning_v3.py`
   - Validuje queries proti pravidl≈Øm (concrete nouns, no verbs, no adjectives)
   - Fixes bƒõ≈æn√© chyby (treaty ‚Üí treaty document, capital ‚Üí city of X)

**‚ùå PROBL√âM - "NUDA VZNIK√Å TADY":**

‚úÖ **Existuje:**
- Query generation z narration text
- Deterministick√© template-based queries
- Keyword extraction z narration

‚ùå **CHYB√ç:**
1. **≈Ω√°dn√° kontrola "coverage":**
   - Nen√≠ tracking "u≈æ m√°me mapu Ruska?" ‚Üí duplicitn√≠ generic queries
   - Nen√≠ tracking "u≈æ m√°me portr√©t Napoleona?" ‚Üí redundance
   - Nen√≠ balance check (80% maps, 0% people portraits)

2. **≈Ω√°dn√Ω dedupe queries:**
   - Scene 1: "Napoleon 1812 archival map"
   - Scene 2: "Napoleon 1812 archival map" 
   - Scene 3: "Napoleon 1812 archival map"
   - ‚Üí STEJN√ù query 3x, proto≈æe nen√≠ global memory

3. **≈Ω√°dn√Ω ranker:**
   - V≈°echny queries jsou considered equal priority
   - Nen√≠ scoring "kter√© query je strategicky nejd≈Øle≈æitƒõj≈°√≠?"
   - Shot_type enum neurƒçuje priority beyond template order

4. **Query je generick√© (m√°lo kontextu sc√©n):**
   - Template `["archival", "map"]` + anchor ‚Üí "Napoleon 1812 archival map"
   - Nereflektuje scene-specific visual intent:
     - Scene o Battle of Borodino ‚Üí nespecifikuje "battle", jen "Napoleon 1812"
     - Scene o Moscow fires ‚Üí nespecifikuje "fire/destruction", jen "Moscow 1812"

**KONKR√âTN√ç P≈ò√çKLAD NUDY:**

```json
// Scene 1 (b_0001): "Napoleon led Grande Arm√©e into Russia"
{
  "search_queries": [
    "Napoleon 1812 archival map public domain archive",
    "Napoleon 1812 historical engraving public domain archive",
    "Napoleon portrait photograph public domain archive"
  ]
}

// Scene 2 (b_0002): "Battle of Borodino, Russian army withdrew"
{
  "search_queries": [
    "Borodino 1812 archival map public domain archive",    // STEJN√ù typ jako scene 1
    "Borodino 1812 historical engraving public domain archive",
    "Alexander portrait photograph public domain archive"
  ]
}

// Scene 3 (b_0003): "Moscow largely deserted"
{
  "search_queries": [
    "Moscow 1812 archival map public domain archive",       // STEJN√ù typ jako scene 1
    "Moscow 1812 historical engraving public domain archive",
    "Moscow portrait photograph public domain archive"
  ]
}
```

**D≈Øsledek:**
- 80% queries jsou variace na "X 1812 archival map/engraving"
- ≈Ω√°dn√° diverzita (documents, letters, battle scenes, civilian life)
- Finder vr√°t√≠ 200 map variants, 0 human stories

---

### **KROK 7: ARCHIVE ASSET RESOLVER (AAR)** ‚ö° **TADY SE PROV√ÅD√ç SEARCH**

**Soubor:** `backend/archive_asset_resolver.py`  
**Funkce:** `resolve_shot_plan_assets()`  
**Volaj√≠c√≠:** `/api/video/resolve-assets/<episode_id>` endpoint

**Flow:**
```
INPUT:
  - shot_plan (z kroku 6)
  - Multi-source searcher (Archive.org, Wikimedia, Europeana)

TRANSFORMACE:
  1. Extract v≈°echny search_queries z shot_plan.scenes[].search_queries[]
  2. Pro ka≈æd√Ω query:
     a) Normalize query (_normalize_query_for_archive_search)
        - Remove low-signal tokens ("archive scan", "original print")
        - Convert spoken years ("eighteen twelve" ‚Üí "1812")
     b) Search multi-source:
        - Archive.org Metadata API
        - Wikimedia Commons API
        - Europeana API (optional)
     c) Filter results:
        - License check (public domain / CC-BY)
        - Mediatype check (image/video only)
        - Quality check (resolution, black frames)
     d) LLM TOPIC RELEVANCE VALIDATION (NEW v14):
        - Vol√° GPT-4o-mini/Vision
        - Validuje: "Is this about Napoleon 1812?" vs "Is this about Tesla Zimbabwe?"
        - Rejects off-topic contamination
     e) Dedupe by visual similarity (optional)
  3. Rank results per query:
     - Relevance score (metadata match)
     - Quality score (resolution, completeness)
     - License priority (public domain > CC-BY > CC-BY-SA)
  4. Select top N assets per scene:
     - Scene duration √∑ asset duration = required count
     - Fallback: global queries if scene has insufficient assets
  5. Generate recommended_subclips[] per asset:
     - Start/end timestamps
     - Duration hints

OUTPUT (archive_manifest.json):
  {
    "version": "aar_v14",
    "episode_id": "ep_024286848837",
    "episode_topic": "Napoleon in Moscow",
    "cache_version": "v14_topic_relevance",
    "global_queries": [
      "Napoleon 1812 Russia campaign historical",
      "French invasion Russia 1812 archival"
    ],
    "scenes": [
      {
        "scene_id": "s_0001",
        "block_id": "b_0001",
        "assets": [
          {
            "asset_id": "asset_0001",
            "archive_item_id": "archive_org:LaLiberationdeParis1944",
            "title": "Napoleon Campaign Map 1812",
            "description": "...",
            "url": "https://archive.org/download/...",
            "thumbnail_url": "...",
            "duration_seconds": 120.5,
            "license": "Public Domain",
            "mediatype": "movies",
            "format": "MPEG4",
            "query_used": "Napoleon 1812 archival map",
            "relevance_score": 0.85,
            "recommended_subclips": [
              {"start": 10.0, "end": 18.0, "duration": 8.0, "reason": "Map overview"}
            ]
          }
        ]
      }
    ],
    "diagnostics": {
      "total_queries": 15,
      "successful_searches": 14,
      "failed_searches": 1,
      "total_assets_found": 127,
      "scenes_with_assets": 7,
      "scenes_without_assets": 0
    }
  }

ULO≈ΩEN√ç:
  - JSON: projects/<episode_id>/archive_manifest.json
  - Cache: projects/<episode_id>/archive_cache/*.json (per-query cache)
```

**KDE SE PROV√ÅD√ç SEARCH:**

1. **Multi-source search (video_sources.py):**
   - `MultiSourceVideoSearcher.search(query, max_results=50)`
   - Paraleln√≠ search nap≈ô√≠ƒç sources:
     - Archive.org: `https://archive.org/advancedsearch.php`
     - Wikimedia: `https://commons.wikimedia.org/w/api.php`
     - Europeana: `https://api.europeana.eu/record/v2/search.json`

2. **Search parameters:**
   - Max results per query: 50 (default)
   - Timeout: 30s per source
   - Retry: 3 attempts with exponential backoff

3. **Ranking logic (`_rank_and_select_candidates`):**
   ```python
   score = (
       relevance_weight * relevance_score +    # 0.4 - metadata match to query
       quality_weight * quality_score +        # 0.3 - resolution/completeness
       license_weight * license_score          # 0.3 - license priority
   )
   ```

**‚ùå PROBL√âM - "NUDA VZNIK√Å TADY":**

‚úÖ **Existuje:**
- Multi-source search (3+ providers)
- License filtering (public domain only)
- Topic relevance validation (LLM-based, v14)
- Quality checks (black frames, resolution)

‚ùå **CHYB√ç:**

1. **≈Ω√°dn√Ω dedupe P≈òED search:**
   - AAR dost√°v√° 35 queries, z toho 15 jsou duplicitn√≠
   - Ka≈æd√Ω duplicitn√≠ query = zbyteƒçn√Ω API call + processing time
   - Nen√≠ pre-search dedupe na query level

2. **≈Ω√°dn√Ω "coverage" tracker:**
   - AAR nem√° p≈ôedstavu "episode balance"
   - Nepoƒç√≠t√°: "u≈æ m√°m 20 map, 2 portr√©ty, 0 dokument≈Ø"
   - Nepou≈æ√≠v√° coverage data k prioritizaci queries

3. **≈Ω√°dn√Ω visual dedupe CROSS-SCENE:**
   - Scene 1 najde map variant A
   - Scene 3 najde map variant A (same item, different query)
   - ‚Üí Duplik√°t v manifestu, proto≈æe nen√≠ global asset registry

4. **Ranking je per-query izolovan√Ω:**
   - Top 5 pro query "Napoleon map" vs top 5 pro query "Moscow map"
   - Nen√≠ global ranking "best 50 assets for whole episode"
   - Nen√≠ strategick√° selekce (balance coverage priorities)

**KONKR√âTN√ç P≈ò√çKLAD NUDY:**

```json
// AAR v√Ωsledek pro episode "Napoleon in Moscow"
{
  "scenes": [
    {
      "scene_id": "s_0001",  // "Napoleon led Grande Arm√©e"
      "assets": [
        {"title": "Russia Map 1812", "query_used": "Napoleon 1812 map"},
        {"title": "Europe Map 1812", "query_used": "Napoleon 1812 map"},
        {"title": "Campaign Map Variant", "query_used": "Grande Arm√©e map"}
      ]
    },
    {
      "scene_id": "s_0002",  // "Battle of Borodino"
      "assets": [
        {"title": "Russia Map 1812", "query_used": "Borodino 1812 map"},      // DUPLICIT!
        {"title": "Battle Map Generic", "query_used": "Borodino map"}
      ]
    },
    {
      "scene_id": "s_0003",  // "Moscow deserted"
      "assets": [
        {"title": "Russia Map 1812", "query_used": "Moscow 1812 map"},        // DUPLICIT!
        {"title": "City Map Generic", "query_used": "Moscow map"}
      ]
    }
  ]
}
```

**D≈Øsledek:**
- 8/10 assets jsou map varianty (80% redundance)
- Nen√≠ visual diverzity (portraits, documents, battle scenes)
- Viewer fatigue: "dal≈°√≠ mapa zase?"

---

### **KROK 8: COMPILATION BUILDER (CB)** 

**Soubor:** `backend/compilation_builder.py`  
**Funkce:** `build_episode_compilation()`  
**Volaj√≠c√≠:** `/api/video/compile/<episode_id>` endpoint

**Flow:**
```
INPUT:
  - archive_manifest.json (z kroku 7)
  - Voiceover MP3 files (z kroku 5)

TRANSFORMACE:
  1. Download assets z URLs v manifestu:
     - Cache check (u≈æ sta≈æeno?)
     - Download s retry (exponential backoff)
     - Save to projects/<episode_id>/archive_cache/
  2. Extract subclips podle recommended_subclips[]:
     - FFmpeg extract: -ss <start> -to <end>
     - Save to temp/subclip_*.mp4
  3. Video stream validation (has_video_stream check):
     - Ffprobe verification each clip has visual content
     - Reject black screen clips
  4. Timeline assembly:
     - Combine subclips podle scene order
     - Sync with voiceover MP3s (audio timeline)
     - Add transitions (optional)
  5. Final render:
     - FFmpeg concat protocol
     - Audio normalization
     - Export to output/final_<episode_id>.mp4

OUTPUT:
  - Final video: output/final_ep_024286848837.mp4
  - Metadata: compilation_report.json

ULO≈ΩEN√ç:
  - Video: output/final_*.mp4
  - Report: projects/<episode_id>/compilation_report.json
```

**‚ùå PROBL√âM:**
- CB je "dumb executor" - pouze sestavuje to, co dostane
- ≈Ω√°dn√° inteligence o visual flow/pacing
- Nen√≠ fallback logika pokud asset sucks (black frames, wrong content)

---

## üì¶ 2) KONTRAKTY / ARTEFAKTY CO SE POU≈Ω√çVAJ√ç

### **Kl√≠ƒçov√© JSON Artifacts v Pipeline**

| Artifact | Gener√°tor | ƒåten√° k√Ωm | Schema keys | Lokace |
|----------|-----------|-----------|-------------|--------|
| **research_report.json** | Research Assistant (LLM) | Narrative, Validator, Composer | `topic, language, timeline[], claims[], entities[]` | `script_state.json ‚Üí metadata.research_report` |
| **draft_script.json** | Narrative Assistant (LLM) | Validator, Composer | `title_candidates[], hook, chapters[], narration_blocks[]` | `script_state.json ‚Üí metadata.draft_script` |
| **validation_result.json** | Validator Assistant (LLM) | Composer | `status, issues[], approved_script` | `script_state.json ‚Üí metadata.validation_result` |
| **tts_ready_package.json** | Composer (deterministic) | TTS Generator, FDA | `episode_id, language, selected_title, narration_blocks[], chapters[]` | `script_state.json ‚Üí metadata.tts_ready_package` |
| **shot_plan.json** | FDA (LLM + deterministic) | AAR, CB | `version, episode_topic, scenes[].search_queries[], shots[]` | `script_state.json ‚Üí metadata.shot_plan` |
| **archive_manifest.json** | AAR (search + LLM validation) | CB | `episode_id, scenes[].assets[], diagnostics` | `projects/<episode_id>/archive_manifest.json` |
| **compilation_report.json** | CB (FFmpeg) | User/Analytics | `video_path, duration, scenes[], errors[]` | `projects/<episode_id>/compilation_report.json` |

---

### **KONTRAKT 1: research_report.json**

**Generuje:** Research Assistant (LLM) v `script_pipeline.py::_step_research()`  
**ƒåte:** Narrative Assistant, Validator, Composer  
**Schema:**

```json
{
  "topic": "string - hlavn√≠ t√©ma epizody",
  "language": "string - ISO code (en, cs)",
  "timeline": [
    {
      "period": "string - ƒçasov√© obdob√≠",
      "event": "string - ud√°lost"
    }
  ],
  "claims": [
    {
      "claim_id": "string - unique ID (c_001, c_002...)",
      "text": "string - verifiable fact",
      "importance": "string - high|medium|low"
    }
  ],
  "entities": [
    {
      "name": "string - entity name",
      "type": "string - person|place|organization|event|other"
    }
  ],
  "open_questions": ["string - research gaps (optional)"]
}
```

**Z√°sadn√≠ kl√≠ƒçe:**
- `claims[]` - backbone faktografick√© integrity
- `entities[]` - pou≈æito pro anchor extraction v FDA
- `timeline[]` - chronologick√Ω kontext (nen√≠ vyu≈æito v AAR!)

**Kde se zapisuje:** `projects/<episode_id>/script_state.json` ‚Üí `metadata.research_report`  
**Kde se ƒçte:** Narrative prompt, Validator cross-check, Composer integrity check

---

### **KONTRAKT 2: tts_ready_package.json**

**Generuje:** Composer (deterministic) v `script_pipeline.py::_deterministic_compose()`  
**ƒåte:** TTS Generator, FDA  
**Schema:**

```json
{
  "episode_id": "string - ep_XXXXX",
  "language": "string - en|cs",
  "selected_title": "string - chosen title",
  "fact_validation_status": "string - PASS|FAIL",
  "chapters": [
    {
      "chapter_id": "string - ch_01",
      "title": "string - chapter title",
      "narration_blocks": [
        {
          "block_id": "string - b_0001",
          "claim_ids": ["string - reference to research claims"],
          "text_tts": "string - TTS-ready narration text"
        }
      ]
    }
  ],
  "narration_blocks": [
    {
      "block_id": "string - b_0001",
      "claim_ids": ["string"],
      "text_tts": "string"
    }
  ],
  "tts_guidelines": {
    "voice_style": "string - documentary_narrator",
    "pace_wpm_hint": "int - 150-180",
    "pause_style": "string - punctuation"
  },
  "metadata": {
    "target_minutes": "int - optional",
    "channel_profile": "string - optional"
  }
}
```

**Z√°sadn√≠ kl√≠ƒçe:**
- `narration_blocks[]` - flat list for TTS (p≈ôes v≈°echny kapitoly)
- `block_id` - unique identifier for sync (TTS ‚Üí FDA ‚Üí AAR ‚Üí CB)
- `text_tts` - fin√°ln√≠ narration text (post-validation)

**Kde se zapisuje:** `script_state.json ‚Üí metadata.tts_ready_package`  
**Kde se ƒçte:**
- TTS Generator: extract `narration_blocks[].text_tts` ‚Üí generate MP3s
- FDA: input pro scene-by-scene shot planning

---

### **KONTRAKT 3: shot_plan.json** ‚ö° **Z√ÅSADN√ç PRO VISUAL PIPELINE**

**Generuje:** FDA (LLM + visual_planning_v3 deterministic compiler)  
**ƒåte:** AAR, CB  
**Schema:**

```json
{
  "version": "string - fda_v2.7",
  "episode_topic": "string - Napoleon in Moscow",
  "scenes": [
    {
      "scene_id": "string - s_0001",
      "block_id": "string - b_0001 (ref to narration_blocks)",
      "narration_summary": "string - short summary (deterministic first sentence)",
      "narration_summary_original": "string - full text_tts",
      "emotion": "string - neutral|tension|tragedy|hope|victory|mystery",
      "cut_rhythm": "string - slow|medium|fast",
      "duration_seconds": "float - estimated speech duration",
      "keywords": ["string - extracted entities/nouns"],
      "search_queries": [
        {
          "query": "string - search query for AAR",
          "reasoning": "string - why this query"
        }
      ],
      "shots": [
        {
          "shot_id": "string - shot_0001",
          "shot_type": "string - historical_battle_footage|maps_context|archival_documents|...",
          "duration_seconds": "float",
          "keywords": ["string"],
          "search_queries": ["string - shot-level queries"]
        }
      ]
    }
  ]
}
```

**Z√°sadn√≠ kl√≠ƒçe:**
- `scenes[].search_queries[]` - **PRIMARY INPUT pro AAR search**
- `scenes[].keywords[]` - fallback anchors pro query refinement
- `shots[].shot_type` - enum urƒçuj√≠c√≠ visual intent (battle, map, document...)

**Kde se zapisuje:** `script_state.json ‚Üí metadata.shot_plan`  
**Kde se ƒçte:**
- AAR: extract all `scenes[].search_queries[].query` ‚Üí search archives
- CB: timeline assembly podle `scenes[]` order

---

### **KONTRAKT 4: archive_manifest.json** ‚ö° **OUTPUT AAR**

**Generuje:** AAR v `archive_asset_resolver.py::resolve_shot_plan_assets()`  
**ƒåte:** CB  
**Schema:**

```json
{
  "version": "string - aar_v14",
  "episode_id": "string",
  "episode_topic": "string",
  "cache_version": "string - v14_topic_relevance",
  "global_queries": ["string - fallback queries"],
  "scenes": [
    {
      "scene_id": "string - s_0001",
      "block_id": "string - b_0001",
      "assets": [
        {
          "asset_id": "string - asset_0001",
          "archive_item_id": "string - archive_org:XXXXX or wikimedia:XXXXX",
          "title": "string",
          "description": "string",
          "url": "string - download URL",
          "thumbnail_url": "string",
          "duration_seconds": "float",
          "license": "string - Public Domain|CC-BY|CC-BY-SA",
          "mediatype": "string - movies|images",
          "format": "string - MPEG4|JPEG",
          "query_used": "string - which query found this",
          "relevance_score": "float - 0.0-1.0",
          "recommended_subclips": [
            {
              "start": "float - seconds",
              "end": "float - seconds",
              "duration": "float",
              "reason": "string - why this subclip"
            }
          ]
        }
      ]
    }
  ],
  "diagnostics": {
    "total_queries": "int",
    "successful_searches": "int",
    "failed_searches": "int",
    "total_assets_found": "int",
    "scenes_with_assets": "int",
    "scenes_without_assets": "int"
  }
}
```

**Z√°sadn√≠ kl√≠ƒçe:**
- `scenes[].assets[]` - konkr√©tn√≠ archive items per scene
- `assets[].recommended_subclips[]` - ƒçasov√© rozsahy pro CB extract
- `diagnostics` - health check (kolik queries failed, kolik sc√©n bez assets)

**Kde se zapisuje:** `projects/<episode_id>/archive_manifest.json`  
**Kde se ƒçte:** CB ‚Üí download URLs, extract subclips

---

## ‚ùå 3) NAJDI P≈òESNƒö "KDE DNES VZNIK√Å NUDA"

### **Systematick√° anal√Ωza nuda-bod≈Ø:**

| # | Component | Chyb√≠ | Proto se dƒõje |
|---|-----------|-------|---------------|
| 1 | **Research Assistant** | Nen√≠ coverage tracking (map/people/documents/places) | Research vrac√≠ flat list entities bez typologie ‚Üí FDA nem√° guidance co prioritize |
| 2 | **FDA Query Generation** | Nen√≠ dedupe queries | Stejn√Ω query ("Napoleon 1812 map") se generuje 10x pro r≈Øzn√© sc√©ny ‚Üí redundantn√≠ search |
| 3 | **FDA Query Generation** | Nen√≠ coverage balance check | Template-based queries generuj√≠ 80% map variants, 0% human portraits/documents |
| 4 | **FDA Query Generation** | Generick√© queries (m√°lo scene-specific context) | "Napoleon 1812 map" m√≠sto "Napoleon 1812 Moscow occupation civilian evacuation" ‚Üí generic results |
| 5 | **AAR Search** | Nen√≠ pre-search dedupe | AAR dost√°v√° 35 queries, z toho 15 duplicitn√≠ch ‚Üí zbyteƒçn√© API calls |
| 6 | **AAR Ranking** | Per-query ranking (not global) | Top 5 for "map" + top 5 for "engraving" bez global "best 50 for episode" ‚Üí local optima |
| 7 | **AAR Asset Selection** | Nen√≠ cross-scene visual dedupe | Scene 1 a Scene 3 dostanou same asset (different query) ‚Üí duplicate visuals in final video |
| 8 | **AAR Asset Selection** | Nen√≠ coverage tracker (episode-level) | Nen√≠ "u≈æ m√°m 20 map, 2 portraits, 0 documents" awareness ‚Üí unbalanced manifest |
| 9 | **CB Assembly** | "Dumb executor" bez visual flow intelligence | Sestav√≠ co dostane, i kdyby to bylo 10 map variants in row ‚Üí viewer fatigue |

---

### **KONKR√âTN√ç BODY: "CHYB√ç X, PROTO SE DƒöJE Y"**

#### **1. CHYB√ç: Coverage Typing in Research**

**Kde:** `script_pipeline.py::_step_research()`  
**Co chyb√≠:** Research entities nemaj√≠ typologie pro visual needs

```json
// SOUƒåASN√ù OUTPUT:
{
  "entities": [
    {"name": "Napoleon", "type": "person"},
    {"name": "Moscow", "type": "place"},
    {"name": "Grande Arm√©e", "type": "organization"}
  ]
}

// MƒöLO BY B√ùT (pro FDA guidance):
{
  "entities": [
    {"name": "Napoleon", "type": "person", "visual_need": "portrait|battle_scene"},
    {"name": "Moscow", "type": "place", "visual_need": "map|cityscape|documents"},
    {"name": "Grande Arm√©e", "type": "organization", "visual_need": "troop_movement|engraving"}
  ],
  "visual_coverage_requirements": {
    "maps": 3,          // need 3 unique maps
    "portraits": 2,     // need 2 portraits (Napoleon, Alexander)
    "documents": 2,     // need 2 documents (treaty, letters)
    "battle_scenes": 1,
    "civilian_life": 1
  }
}
```

**Proto se dƒõje:** FDA nem√° guidance ‚Üí generuje template-based queries bez balance awareness

---

#### **2. CHYB√ç: Query Dedupe in FDA**

**Kde:** `footage_director.py::run_fda_llm()` + `visual_planning_v3.py::_queries_for_scene()`  
**Co chyb√≠:** Global query registry p≈ôed emission

```python
# SOUƒåASN√ù K√ìD (visual_planning_v3.py, line 454-513):
def _queries_for_scene(text, focus_entities, shot_types):
    # Generuje 5 queries per scene
    # ≈Ω√ÅDN√ù CHECK jestli query u≈æ byl pou≈æit v previous sc√©n√°ch
    return queries  # m≈Ø≈æe obsahovat duplicity cross-scene

# MƒöLO BY B√ùT:
_global_query_registry = set()  # tracks u≈æ pou≈æit√© queries

def _queries_for_scene_dedupe(text, focus_entities, shot_types, used_queries):
    candidates = _generate_query_candidates(text, focus_entities, shot_types, count=10)
    
    # Dedupe against already used queries
    unique = []
    for q in candidates:
        if q not in used_queries:
            unique.append(q)
            used_queries.add(q)
        if len(unique) >= 5:
            break
    
    # Fallback: pokud nen√≠ 5 unique, generate alternates
    while len(unique) < 5:
        alternate = _generate_alternate_query(text, focus_entities, avoid=used_queries)
        unique.append(alternate)
        used_queries.add(alternate)
    
    return unique
```

**Proto se dƒõje:** Duplicitn√≠ queries ‚Üí redundantn√≠ API calls v AAR ‚Üí same results 3x

---

#### **3. CHYB√ç: Coverage Balance Check in FDA**

**Kde:** `visual_planning_v3.py::compile_scene_plan_to_shot_plan()`  
**Co chyb√≠:** Episode-level coverage tracker pro query generation

```python
# MƒöLO BY B√ùT:
class EpisodeCoverageTracker:
    def __init__(self, target_coverage):
        self.target = target_coverage  # {"maps": 3, "portraits": 2, "documents": 2}
        self.current = {"maps": 0, "portraits": 0, "documents": 0}
    
    def needs_more(self, visual_type):
        return self.current.get(visual_type, 0) < self.target.get(visual_type, 0)
    
    def increment(self, visual_type):
        self.current[visual_type] = self.current.get(visual_type, 0) + 1
    
    def get_priority_types(self):
        # Vr√°t√≠ typy sorted by deficit
        deficit = []
        for vtype, target_count in self.target.items():
            current_count = self.current.get(vtype, 0)
            if current_count < target_count:
                deficit.append((vtype, target_count - current_count))
        return sorted(deficit, key=lambda x: x[1], reverse=True)

# Pou≈æit√≠ p≈ôi query generation:
def _queries_for_scene_with_coverage(text, entities, shot_types, coverage_tracker):
    priority_types = coverage_tracker.get_priority_types()
    
    # Generate queries PRIORITIZING deficitn√≠ types
    queries = []
    for visual_type, deficit in priority_types:
        if deficit > 0:
            query = _generate_typed_query(text, entities, visual_type)
            queries.append(query)
            coverage_tracker.increment(visual_type)
    
    return queries
```

**Proto se dƒõje:** Template-based queries ignoruj√≠ episode balance ‚Üí 80% maps, 0% diversity

---

#### **4. CHYB√ç: Scene-Specific Context in Queries**

**Kde:** `visual_planning_v3.py::_queries_for_scene()` line 492-506  
**Co chyb√≠:** Query context beyond entity + year

```python
# SOUƒåASN√ù K√ìD:
# Template: ["archival", "map"] + entity + year ‚Üí "Napoleon 1812 archival map"

# MƒöLO BY B√ùT (inject scene intent):
def _build_contextual_query(text, entity, year, visual_type, shot_type):
    """
    Build query with scene-specific context, not just template.
    """
    # Extract action/event from narration
    action_keywords = extract_action_context(text)  
    # e.g., "Battle of Borodino" ‚Üí action: "battle"
    # e.g., "Moscow fires broke out" ‚Üí action: "fire", "destruction"
    
    if visual_type == "map":
        if "battle" in action_keywords:
            return f"{entity} {year} battle map tactical"
        elif "retreat" in action_keywords:
            return f"{entity} {year} retreat route map"
        else:
            return f"{entity} {year} campaign map"
    
    elif visual_type == "engraving":
        if "battle" in action_keywords:
            return f"{entity} {year} battle scene engraving"
        elif "civilian" in action_keywords:
            return f"{entity} {year} civilian life engraving"
        else:
            return f"{entity} {year} historical engraving"

# EXAMPLE OUTPUT:
# Scene "Battle of Borodino" ‚Üí "Napoleon 1812 battle map tactical"
# Scene "Moscow fires" ‚Üí "Moscow 1812 fire destruction aftermath"
# m√≠sto generic "Napoleon 1812 archival map" 10x
```

**Proto se dƒõje:** Generic queries ‚Üí generic results ‚Üí nuda

---

#### **5. CHYB√ç: Pre-Search Dedupe in AAR**

**Kde:** `archive_asset_resolver.py::resolve_shot_plan_assets()`  
**Co chyb√≠:** Query normalization + dedupe p≈ôed multi-source search

```python
# SOUƒåASN√ù K√ìD:
# Pro ka≈æd√Ω scene.search_queries[]: search immediately (no global dedupe)

# MƒöLO BY B√ùT:
def resolve_shot_plan_assets_with_dedupe(shot_plan, ...):
    # 1. Extract ALL queries from all scenes
    all_queries = []
    for scene in shot_plan["scenes"]:
        for sq in scene.get("search_queries", []):
            all_queries.append({
                "query": sq["query"],
                "scene_id": scene["scene_id"],
                "reasoning": sq.get("reasoning", "")
            })
    
    # 2. Normalize + dedupe queries
    unique_queries = {}
    for q in all_queries:
        normalized = normalize_query(q["query"])
        if normalized not in unique_queries:
            unique_queries[normalized] = {
                "query": q["query"],
                "scene_ids": [q["scene_id"]],
                "reasoning": q["reasoning"]
            }
        else:
            # Merge scene_ids for shared query
            unique_queries[normalized]["scene_ids"].append(q["scene_id"])
    
    print(f"Dedupe: {len(all_queries)} queries ‚Üí {len(unique_queries)} unique")
    
    # 3. Search ONLY unique queries
    search_results = {}
    for norm_q, meta in unique_queries.items():
        results = multi_source_search(meta["query"])
        search_results[norm_q] = results
    
    # 4. Distribute results zpƒõt do sc√©n
    for scene in shot_plan["scenes"]:
        scene_assets = []
        for sq in scene.get("search_queries", []):
            norm = normalize_query(sq["query"])
            if norm in search_results:
                scene_assets.extend(search_results[norm])
        # Dedupe assets per scene (by archive_item_id)
        scene["assets"] = dedupe_assets_by_id(scene_assets)
```

**Proto se dƒõje:** 35 queries ‚Üí 15 duplicitn√≠ch ‚Üí waste API calls + processing time

---

#### **6. CHYB√ç: Global Ranking (Not Per-Query)**

**Kde:** `archive_asset_resolver.py::_rank_and_select_candidates()`  
**Co chyb√≠:** Episode-level ranking across all found assets

```python
# SOUƒåASN√ù K√ìD:
# Per-query ranking: top 5 for each query independently

# MƒöLO BY B√ùT:
def global_ranking_for_episode(all_assets, episode_context, coverage_tracker):
    """
    Rank ALL assets found across all queries, then select strategically.
    
    Scoring factors:
    - Relevance to episode topic (LLM score)
    - Quality (resolution, completeness)
    - Coverage priority (balance types)
    - Visual uniqueness (avoid similar assets)
    """
    scored_assets = []
    for asset in all_assets:
        score = (
            asset["relevance_score"] * 0.3 +
            asset["quality_score"] * 0.2 +
            coverage_priority_score(asset, coverage_tracker) * 0.3 +
            uniqueness_score(asset, scored_assets) * 0.2
        )
        scored_assets.append({**asset, "global_score": score})
    
    # Sort by global score
    ranked = sorted(scored_assets, key=lambda x: x["global_score"], reverse=True)
    
    # Select top N ensuring coverage balance
    selected = []
    for asset in ranked:
        if len(selected) >= target_count:
            break
        # Check coverage balance
        asset_type = infer_visual_type(asset)
        if coverage_tracker.can_add(asset_type):
            selected.append(asset)
            coverage_tracker.increment(asset_type)
    
    return selected

def coverage_priority_score(asset, coverage_tracker):
    """
    Higher score if asset type is under-represented.
    """
    asset_type = infer_visual_type(asset)
    deficit = coverage_tracker.deficit(asset_type)
    return min(1.0, deficit / 3.0)  # normalize 0-1
```

**Proto se dƒõje:** Local optima per query ‚Üí unbalanced final selection

---

#### **7. CHYB√ç: Cross-Scene Visual Dedupe**

**Kde:** `archive_asset_resolver.py::resolve_shot_plan_assets()`  
**Co chyb√≠:** Global asset registry to prevent duplicates across scenes

```python
# SOUƒåASN√ù K√ìD:
# Scene 1 gets assets independently
# Scene 2 gets assets independently
# ‚Üí Same asset can appear in both (different queries)

# MƒöLO BY B√ùT:
_global_asset_registry = {}  # {archive_item_id: [scene_ids]}

def assign_assets_to_scenes_with_dedupe(scenes, all_ranked_assets):
    """
    Assign assets to scenes while preventing cross-scene duplicates.
    """
    for scene in scenes:
        scene_assets = []
        needed_duration = scene["duration_seconds"]
        covered_duration = 0
        
        for asset in all_ranked_assets:
            aid = asset["archive_item_id"]
            
            # Skip if already used in another scene
            if aid in _global_asset_registry:
                continue
            
            # Check if asset matches scene context
            if matches_scene(asset, scene):
                scene_assets.append(asset)
                _global_asset_registry[aid] = scene["scene_id"]
                covered_duration += asset["duration_seconds"]
                
                if covered_duration >= needed_duration:
                    break
        
        scene["assets"] = scene_assets
```

**Proto se dƒõje:** Same asset in multiple scenes ‚Üí visual repetition ‚Üí nuda

---

#### **8. CHYB√ç: Episode-Level Coverage Tracker in AAR**

**Kde:** `archive_asset_resolver.py::resolve_shot_plan_assets()`  
**Co chyb√≠:** Awareness of episode balance during asset selection

```python
# MƒöLO BY B√ùT:
class AAR_CoverageTracker:
    def __init__(self, target_coverage):
        self.target = target_coverage  # from Research/FDA
        self.current = {vtype: 0 for vtype in target_coverage.keys()}
        self.assigned_assets = []
    
    def infer_type(self, asset):
        """Classify asset into visual type (map/portrait/document/...)"""
        title_lower = asset["title"].lower()
        desc_lower = asset["description"].lower()
        
        if "map" in title_lower or "carte" in desc_lower:
            return "maps"
        elif "portrait" in title_lower or "photograph" in desc_lower:
            return "portraits"
        elif "document" in title_lower or "letter" in desc_lower:
            return "documents"
        elif "battle" in title_lower or "combat" in desc_lower:
            return "battle_scenes"
        else:
            return "other"
    
    def can_add(self, visual_type):
        """Check if we still need more of this type"""
        current = self.current.get(visual_type, 0)
        target = self.target.get(visual_type, float('inf'))
        return current < target
    
    def add_asset(self, asset):
        vtype = self.infer_type(asset)
        self.current[vtype] = self.current.get(vtype, 0) + 1
        self.assigned_assets.append(asset)
    
    def get_balance_report(self):
        return {
            vtype: {
                "target": self.target.get(vtype, 0),
                "current": self.current.get(vtype, 0),
                "deficit": self.target.get(vtype, 0) - self.current.get(vtype, 0)
            }
            for vtype in self.target.keys()
        }

# Usage during asset selection:
coverage = AAR_CoverageTracker(episode_coverage_requirements)
for asset in ranked_assets:
    vtype = coverage.infer_type(asset)
    if coverage.can_add(vtype):
        assign_to_scene(asset, scene)
        coverage.add_asset(asset)

print(f"Coverage balance: {coverage.get_balance_report()}")
```

**Proto se dƒõje:** Nen√≠ tracking ‚Üí 80% maps, 0% portraits ‚Üí nuda

---

## üîß 4) INTEGRAƒåN√ç BOD PRO 2 AI ASISTENTY

### **N√°vrh: Query Director + Visual Curator**

---

### **AI ASISTENT #1: QUERY DIRECTOR** 
**‚ö° Zapojen√≠: P≈òED scrapers (mezi FDA a AAR)**

#### **ROLE:**
Transformuje raw FDA queries ‚Üí strategick√©, coverage-aware queries

#### **VSTUP (co dostane):**

```json
{
  "episode_context": {
    "episode_id": "ep_024286848837",
    "episode_topic": "Napoleon in Moscow: The 1812 Occupation",
    "target_duration_minutes": 8,
    "research_entities": [
      {"name": "Napoleon", "type": "person"},
      {"name": "Moscow", "type": "place"},
      {"name": "Grande Arm√©e", "type": "organization"}
    ]
  },
  "coverage_requirements": {
    "maps": 3,
    "portraits": 2,
    "documents": 2,
    "battle_scenes": 1,
    "civilian_life": 1
  },
  "raw_queries_by_scene": [
    {
      "scene_id": "s_0001",
      "block_id": "b_0001",
      "narration_summary": "Napoleon led Grande Arm√©e into Russia...",
      "fda_queries": [
        "Napoleon 1812 archival map public domain",
        "Grande Arm√©e historical engraving public domain"
      ]
    },
    {
      "scene_id": "s_0002",
      "block_id": "b_0002",
      "narration_summary": "Battle of Borodino, Russian army withdrew...",
      "fda_queries": [
        "Borodino 1812 archival map public domain",
        "Alexander portrait public domain"
      ]
    }
  ]
}
```

#### **V√ùSTUP (co mus√≠ vr√°tit):**

```json
{
  "query_director_version": "v1.0",
  "episode_id": "ep_024286848837",
  "strategic_queries": [
    {
      "query_id": "qd_001",
      "query": "Napoleon Bonaparte 1812 portrait official Louvre",
      "priority": "critical",
      "visual_type": "portraits",
      "reasoning": "Episode needs Napoleon portrait - highest priority",
      "intended_scenes": ["s_0001", "s_0005"],
      "estimated_results": 50
    },
    {
      "query_id": "qd_002",
      "query": "Grande Arm√©e 1812 Russia invasion campaign map tactical",
      "priority": "high",
      "visual_type": "maps",
      "reasoning": "Primary geographic context for invasion narrative",
      "intended_scenes": ["s_0001", "s_0002"],
      "estimated_results": 30
    },
    {
      "query_id": "qd_003",
      "query": "Tsar Alexander I Russia 1812 portrait official",
      "priority": "high",
      "visual_type": "portraits",
      "reasoning": "Main antagonist - needed for diplomatic context",
      "intended_scenes": ["s_0004", "s_0006"],
      "estimated_results": 40
    },
    {
      "query_id": "qd_004",
      "query": "Moscow 1812 fire destruction aftermath engraving",
      "priority": "medium",
      "visual_type": "battle_scenes",
      "reasoning": "Scene-specific: Moscow fires chapter needs destruction visuals",
      "intended_scenes": ["s_0003"],
      "estimated_results": 25
    },
    {
      "query_id": "qd_005",
      "query": "French Russian treaty document 1807 Tilsit handwritten",
      "priority": "medium",
      "visual_type": "documents",
      "reasoning": "Coverage balance: need document visuals for variety",
      "intended_scenes": ["s_0001"],
      "estimated_results": 15
    }
  ],
  "dedupe_report": {
    "input_queries_count": 14,
    "deduplicated_queries_count": 9,
    "strategic_queries_count": 5,
    "coverage_balanced": true
  },
  "coverage_plan": {
    "maps": {"target": 3, "queries": 1},
    "portraits": {"target": 2, "queries": 2},
    "documents": {"target": 2, "queries": 1},
    "battle_scenes": {"target": 1, "queries": 1},
    "civilian_life": {"target": 1, "queries": 0}
  }
}
```

#### **DO JAK√âHO ARTEFAKTU SE ULO≈Ω√ç:**

**Nov√Ω artefakt:** `projects/<episode_id>/query_director_output.json`

Struktura:
```json
{
  "version": "qd_v1.0",
  "generated_at": "2025-01-05T12:00:00Z",
  "episode_id": "ep_024286848837",
  "strategic_queries": [...],
  "coverage_plan": {...},
  "metadata": {
    "input_source": "fda_v2.7_shot_plan",
    "llm_provider": "openrouter",
    "llm_model": "anthropic/claude-3.5-sonnet",
    "processing_time_seconds": 15.3
  }
}
```

**Integraƒçn√≠ flow:**
```
FDA ‚Üí shot_plan.json
  ‚Üì
Query Director (NEW!) ‚Üí query_director_output.json
  ‚Üì
AAR (modified to read query_director_output.json instead of shot_plan queries)
```

---

### **AI ASISTENT #2: VISUAL CURATOR**
**‚ö° Zapojen√≠: PO fetchi, P≈òED shotplanem (mezi AAR search results a manifest finalization)**

#### **ROLE:**
Rank, dedupe, select nejlep≈°√≠ assets z raw search results

#### **VSTUP (co dostane):**

```json
{
  "episode_context": {
    "episode_id": "ep_024286848837",
    "episode_topic": "Napoleon in Moscow: The 1812 Occupation",
    "total_duration_seconds": 480,
    "coverage_requirements": {
      "maps": 3,
      "portraits": 2,
      "documents": 2,
      "battle_scenes": 1
    }
  },
  "raw_search_results": [
    {
      "query_id": "qd_001",
      "query": "Napoleon Bonaparte 1812 portrait",
      "results_count": 50,
      "results": [
        {
          "asset_id": "aar_raw_001",
          "archive_item_id": "archive_org:NapoleonPortrait1812",
          "title": "Napoleon Bonaparte - Official Portrait 1812",
          "description": "Oil painting by Jacques-Louis David...",
          "url": "https://archive.org/download/...",
          "thumbnail_url": "https://archive.org/services/img/...",
          "duration_seconds": 0,  // image
          "license": "Public Domain",
          "mediatype": "image",
          "format": "JPEG",
          "resolution": "3000x4000",
          "file_size_mb": 2.5,
          "query_used": "Napoleon Bonaparte 1812 portrait"
        }
        // ... 49 more results
      ]
    },
    {
      "query_id": "qd_002",
      "query": "Grande Arm√©e 1812 Russia campaign map",
      "results_count": 30,
      "results": [...]
    }
    // ... more query results
  ],
  "scenes": [
    {
      "scene_id": "s_0001",
      "block_id": "b_0001",
      "narration_summary": "Napoleon led Grande Arm√©e into Russia...",
      "duration_seconds": 18.5,
      "emotion": "neutral",
      "intended_visual_types": ["maps", "portraits"]
    }
  ]
}
```

#### **V√ùSTUP (co mus√≠ vr√°tit):**

```json
{
  "visual_curator_version": "v1.0",
  "episode_id": "ep_024286848837",
  "curated_assets": [
    {
      "asset_id": "curated_001",
      "archive_item_id": "archive_org:NapoleonPortrait1812",
      "title": "Napoleon Bonaparte - Official Portrait 1812",
      "description": "Oil painting by Jacques-Louis David...",
      "url": "https://archive.org/download/...",
      "thumbnail_url": "...",
      "duration_seconds": 0,
      "license": "Public Domain",
      "mediatype": "image",
      "visual_type": "portraits",  // CLASSIFIED by Curator
      "global_rank": 1,
      "global_score": 0.95,
      "quality_assessment": {
        "resolution": "excellent",
        "composition": "professional",
        "relevance": "perfect",
        "uniqueness": "high"
      },
      "curator_reasoning": "Primary portrait of Napoleon - highest quality, official, perfectly matches episode topic",
      "recommended_scenes": ["s_0001", "s_0005"],
      "recommended_subclips": [
        {
          "start": 0,
          "duration": 8.0,
          "zoom_level": "medium_closeup",
          "reason": "Focus on Napoleon's face for intro"
        }
      ]
    },
    {
      "asset_id": "curated_002",
      "archive_item_id": "archive_org:RussiaCampaignMap1812",
      "title": "Grande Arm√©e Russia Invasion Campaign Map 1812",
      "visual_type": "maps",
      "global_rank": 2,
      "global_score": 0.92,
      "quality_assessment": {
        "resolution": "excellent",
        "composition": "clear",
        "relevance": "excellent",
        "uniqueness": "high"
      },
      "curator_reasoning": "Primary geographic context - shows full invasion route, high quality scan",
      "recommended_scenes": ["s_0001", "s_0002"],
      "recommended_subclips": [...]
    }
    // ... top 15-20 curated assets (z 200+ raw results)
  ],
  "dedupe_report": {
    "input_assets_count": 237,
    "duplicates_removed": 52,
    "low_quality_rejected": 31,
    "off_topic_rejected": 18,
    "curated_assets_count": 20
  },
  "coverage_balance": {
    "maps": {"target": 3, "selected": 3, "status": "met"},
    "portraits": {"target": 2, "selected": 2, "status": "met"},
    "documents": {"target": 2, "selected": 2, "status": "met"},
    "battle_scenes": {"target": 1, "selected": 1, "status": "met"},
    "civilian_life": {"target": 1, "selected": 0, "status": "deficit"}
  },
  "quality_metrics": {
    "average_global_score": 0.87,
    "resolution_excellent_pct": 75,
    "relevance_excellent_pct": 85
  }
}
```

#### **DO JAK√âHO ARTEFAKTU SE ULO≈Ω√ç:**

**Modifikace existuj√≠c√≠ho:** `projects/<episode_id>/archive_manifest.json`

P≈ôid√° sekce:
```json
{
  "version": "aar_v15_with_curator",
  "episode_id": "ep_024286848837",
  
  // EXISTING (AAR raw results):
  "raw_search_results": {
    "total_queries": 5,
    "total_results": 237,
    "results_by_query": [...]
  },
  
  // NEW (Visual Curator output):
  "curator_output": {
    "version": "vc_v1.0",
    "curated_at": "2025-01-05T12:05:00Z",
    "curated_assets": [...],  // from Curator output
    "dedupe_report": {...},
    "coverage_balance": {...},
    "quality_metrics": {...}
  },
  
  // MODIFIED (sc√©ny dost√°vaj√≠ curated assets m√≠sto raw):
  "scenes": [
    {
      "scene_id": "s_0001",
      "block_id": "b_0001",
      "assets": [
        // Reference to curated_assets[] by asset_id
        {"asset_id": "curated_001", "usage": "primary"},
        {"asset_id": "curated_002", "usage": "secondary"}
      ]
    }
  ]
}
```

**Integraƒçn√≠ flow:**
```
AAR search ‚Üí raw_search_results (237 assets)
  ‚Üì
Visual Curator (NEW!) ‚Üí curated_assets (20 best)
  ‚Üì
AAR manifest finalization ‚Üí assign curated assets to scenes
  ‚Üì
CB (reads manifest.scenes[].assets[] which now point to curated_assets)
```

---

## üìä SROVN√ÅN√ç: P≈òED vs. PO (s 2 AI asistenty)

### **P≈òED (souƒçasn√Ω stav):**

| F√°ze | Poƒçet queries | Dedupe? | Coverage aware? | Ranking | Result |
|------|---------------|---------|-----------------|---------|--------|
| FDA | 35 queries (7 sc√©n √ó 5 queries) | ‚ùå | ‚ùå | N/A | 15 duplicitn√≠ch queries |
| AAR Search | 35 API calls | ‚ùå | ‚ùå | Per-query top 5 | 237 raw results |
| AAR Selection | N/A | ‚ùå cross-scene | ‚ùå | Local optima | 80% maps, 20% other |
| CB Assembly | N/A | N/A | N/A | N/A | 10 map variants in row ‚Üí nuda |

**Probl√©m:** Generick√© queries ‚Üí redundantn√≠ results ‚Üí unbalanced selection ‚Üí nuda

---

### **PO (s Query Director + Visual Curator):**

| F√°ze | Poƒçet queries | Dedupe? | Coverage aware? | Ranking | Result |
|------|---------------|---------|-----------------|---------|--------|
| FDA | 35 raw queries | N/A | N/A | N/A | Raw creative output |
| **Query Director** | **5 strategic queries** | **‚úÖ** | **‚úÖ** | **Priority-based** | **Deduplicated + balanced** |
| AAR Search | **5 API calls** (7√ó efektivnƒõj≈°√≠) | ‚úÖ | ‚úÖ | N/A | 200+ raw results |
| **Visual Curator** | **N/A** | **‚úÖ** | **‚úÖ** | **Global ranking** | **20 best assets, coverage balanced** |
| CB Assembly | N/A | ‚úÖ | ‚úÖ | N/A | Diverse visuals, no repetition |

**V√Ωsledek:** Strategick√© queries ‚Üí kvalitn√≠ results ‚Üí balanced selection ‚Üí NO nuda

---

## üéØ SUMMARY: Kl√≠ƒçov√© body pro n√°vrh

### **Souƒçasn√© flow probl√©my:**

1. **Research ‚Üí FDA:** ≈Ω√°dn√° visual coverage guidance
2. **FDA query generation:** Template-based, generick√©, redundantn√≠
3. **AAR search:** Pl√Ωtv√° API calls na duplicitn√≠ queries
4. **AAR selection:** Per-query ranking, nen√≠ global/coverage aware
5. **CB assembly:** Dumb executor, nem√° control nad visual flow

### **Integraƒçn√≠ body pro 2 AI asistenty:**

| Asistent | Zapojen√≠ | Vstup | V√Ωstup | Artefakt |
|----------|----------|-------|--------|----------|
| **Query Director** | Mezi FDA a AAR | shot_plan.json (raw queries) + coverage_requirements | strategic_queries[] (deduplicated, coverage-aware) | query_director_output.json |
| **Visual Curator** | Mezi AAR search a manifest | raw_search_results[] (237 assets) + coverage_requirements | curated_assets[] (top 20, balanced) | archive_manifest.json (curator_output section) |

### **Source Pack p≈ôipraven√≠:**

Pro Query Director + Curator:
1. **Research entities** ‚Üí ADD visual typing (`visual_need: "portrait|map|document"`)
2. **Coverage requirements** ‚Üí NEW artifact (research_coverage_plan.json)
3. **AAR raw results** ‚Üí SEPARATE from curated (keep both in manifest)
4. **Scene-asset assignment** ‚Üí USE curated_assets[] (not raw results)

---

**KONEC ANAL√ùZY**

Tento dokument poskytuje 100% p≈ôesn√Ω snapshot souƒçasn√© architektury pro n√°vrh Query Director + Visual Curator integrace.


