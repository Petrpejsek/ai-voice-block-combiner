# Topic Intelligence Assistant - LLM Settings Update

## âœ… Co bylo pÅ™idÃ¡no

PÅ™idÃ¡na **konfigurace LLM nastavenÃ­** pro Topic Intelligence Assistant, stejnÄ› jako u ostatnÃ­ch asistentÅ¯ v aplikaci.

### NovÃ© funkce

1. **TlaÄÃ­tko âš™ï¸ LLM Settings** v hlaviÄce Topic Intelligence panelu
2. **Modal okno** s nastavenÃ­m:
   - **Provider:** OpenRouter (jedinÃ½ podporovanÃ½)
   - **Model:** VÃ½bÄ›r z populÃ¡rnÃ­ch modelÅ¯ (GPT-4o, Claude, Gemini, Llama...)
   - **Temperature:** Slider 0.0-2.0 (deterministic â†’ creative)
   - **Custom Prompt:** VolitelnÃ© dodateÄnÃ© instrukce

### ZmÄ›ny v kÃ³du

**Frontend (`TopicIntelligencePanel.js`):**
- PÅ™idÃ¡n state `llmConfig` s vÃ½chozÃ­mi hodnotami
- PÅ™idÃ¡no tlaÄÃ­tko "âš™ï¸ LLM Settings" vedle nadpisu
- PÅ™idÃ¡n modal s formulÃ¡Å™em pro nastavenÃ­
- Konfigurace se posÃ­lÃ¡ v requestu na backend

**Backend (`app.py`):**
- Endpoint `/api/topic-intel/research` pÅ™ijÃ­mÃ¡ novÃ½ parametr `llm_config`
- Validace OpenRouter API klÃ­Äe (mÃ­sto OpenAI)
- PÅ™edÃ¡nÃ­ konfigurace do service

**Backend Service (`topic_intel_service.py`):**
- NovÃ¡ funkce `call_openai_openrouter()` pro volÃ¡nÃ­ OpenRouter API
- `research()` metoda pÅ™ijÃ­mÃ¡ LLM parametry
- `_expand_topics()` pouÅ¾Ã­vÃ¡ konfiguraci a custom prompt

## ğŸš€ Jak pouÅ¾Ã­vat

### 1. OtevÅ™Ã­t nastavenÃ­

1. OtevÅ™i frontend: `http://localhost:4000`
2. Scrolluj dolÅ¯ k "ğŸ”¬ Topic Intelligence (US)" panelu
3. Klikni na tlaÄÃ­tko **"âš™ï¸ LLM Settings"** vpravo nahoÅ™e

### 2. Nastavit LLM

**Provider:**
- Pouze OpenRouter (automaticky)

**Model (vÃ½bÄ›r):**
- `openai/gpt-4o` (doporuÄeno) - nejlepÅ¡Ã­ kvalita
- `openai/gpt-4o-mini` - rychlejÅ¡Ã­, levnÄ›jÅ¡Ã­
- `anthropic/claude-3.5-sonnet` - alternativa
- `anthropic/claude-3-opus` - nejvyÅ¡Å¡Ã­ kvalita
- `google/gemini-pro-1.5` - Google model
- `meta-llama/llama-3.1-70b-instruct` - open-source

**Temperature (0.0-2.0):**
- **0.0-0.5:** DeterministickÃ½, konzistentnÃ­ vÃ½sledky
- **0.5-1.0:** VyvÃ¡Å¾enÃ½ (doporuÄeno: 0.7)
- **1.0-2.0:** KreativnÃ­, rozmanitÃ© vÃ½sledky

**Custom Prompt (volitelnÃ©):**
```
Focus on 20th century topics
```
nebo
```
Emphasize scientific discoveries and technological breakthroughs
```

### 3. UloÅ¾it a spustit research

1. Klikni "Save Settings"
2. Nastav poÄet doporuÄenÃ­ a ÄasovÃ© okno
3. Klikni "Start Research"
4. LLM pouÅ¾ije tvou konfiguraci

## ğŸ“‹ PoÅ¾adavky

### API KlÃ­Äe

**OpenRouter API klÃ­Ä (povinnÃ½):**

```bash
# backend/.env
OPENROUTER_API_KEY=sk-or-v1-...your-key...
```

ZÃ­skej na: https://openrouter.ai/keys

### Feature Flag

```bash
# backend/.env
TOPIC_INTEL_ENABLED=true
```

### Restart backendu

```bash
cd backend
python3 app.py
```

## ğŸ¯ PÅ™Ã­klady pouÅ¾itÃ­

### ZÃ¡kladnÃ­ research (vÃ½chozÃ­ nastavenÃ­)

- Model: `openai/gpt-4o`
- Temperature: `0.7`
- Custom prompt: (prÃ¡zdnÃ©)

â†’ VyvÃ¡Å¾enÃ½ mix tÃ©mat s thriller/mystery framing

### KreativnÃ­ research

- Model: `anthropic/claude-3.5-sonnet`
- Temperature: `1.2`
- Custom prompt: "Focus on untold stories and conspiracy theories"

â†’ NeobvyklÃ©, kreativnÃ­ tÃ©mata

### ZamÄ›Å™enÃ½ research

- Model: `openai/gpt-4o-mini`
- Temperature: `0.3`
- Custom prompt: "Only topics from World War 2 era"

â†’ SpecifickÃ¡, konzistentnÃ­ tÃ©mata

### LevnÃ½/rychlÃ½ research

- Model: `openai/gpt-4o-mini`
- Temperature: `0.7`
- Custom prompt: (prÃ¡zdnÃ©)

â†’ RychlejÅ¡Ã­ odpovÄ›Ä, niÅ¾Å¡Ã­ cena

## ğŸ”§ TechnickÃ© detaily

### OpenRouter API

```python
# Endpoint
POST https://openrouter.ai/api/v1/chat/completions

# Headers
Authorization: Bearer sk-or-v1-...
Content-Type: application/json

# Body
{
  "model": "openai/gpt-4o",
  "messages": [...],
  "temperature": 0.7
}
```

### Request formÃ¡t (frontend â†’ backend)

```json
{
  "count": 20,
  "window_days": 7,
  "llm_config": {
    "provider": "openrouter",
    "model": "openai/gpt-4o",
    "temperature": 0.7,
    "custom_prompt": "Focus on 20th century"
  }
}
```

### Custom Prompt integrace

Custom prompt se pÅ™idÃ¡ na konec zÃ¡kladnÃ­ho promptu:

```
[ZÃ¡kladnÃ­ prompt s archetypes, seeds, requirements...]

**Additional Instructions:**
{custom_prompt}

[Output format...]
```

## ğŸ’¡ Tipy

1. **ZaÄni s vÃ½chozÃ­m nastavenÃ­m** (GPT-4o, temp 0.7)
2. **ZvyÅ¡ temperature** (â†’ 1.0-1.5) pokud chceÅ¡ diverzitu
3. **SniÅ¾ temperature** (â†’ 0.3-0.5) pro konzistentnÃ­ vÃ½sledky
4. **PouÅ¾ij custom prompt** pro specifickÃ¡ tÃ©mata
5. **Zkus rÅ¯znÃ© modely** - kaÅ¾dÃ½ mÃ¡ jinÃ½ "styl"

## ğŸ› Troubleshooting

### "OpenRouter API key not configured"

**Fix:**
```bash
# PÅ™idej do backend/.env
OPENROUTER_API_KEY=sk-or-v1-...

# Restart backend
cd backend && python3 app.py
```

### LLM vracÃ­ prÃ¡zdnÃ© vÃ½sledky

**MoÅ¾nÃ© pÅ™Ã­Äiny:**
- Custom prompt je pÅ™Ã­liÅ¡ restriktivnÃ­
- Temperature je pÅ™Ã­liÅ¡ nÃ­zko (0.0-0.1)
- Model nepodporuje JSON output

**Fix:**
- Zkus zvÃ½Å¡it temperature na 0.5+
- OdstraÅˆ/zmÃ­rni custom prompt
- PouÅ¾ij `openai/gpt-4o` (nejspolehlivÄ›jÅ¡Ã­)

### VÃ½sledky jsou "off-topic"

**Fix:**
- SniÅ¾ temperature na 0.5 nebo nÃ­Å¾
- PÅ™idej specifickÃ½ custom prompt:
  ```
  Only suggest topics that are directly related to documented historical events.
  Avoid speculative or conspiracy-focused topics.
  ```

## ğŸ“Š SrovnÃ¡nÃ­ modelÅ¯

| Model | Rychlost | Kvalita | Cena | DoporuÄenÃ­ |
|-------|----------|---------|------|------------|
| openai/gpt-4o | âš¡âš¡âš¡ | â­â­â­â­â­ | $$ | **Best overall** |
| openai/gpt-4o-mini | âš¡âš¡âš¡âš¡âš¡ | â­â­â­â­ | $ | Best value |
| claude-3.5-sonnet | âš¡âš¡âš¡ | â­â­â­â­â­ | $$$ | Most creative |
| claude-3-opus | âš¡âš¡ | â­â­â­â­â­ | $$$$ | Highest quality |
| gemini-pro-1.5 | âš¡âš¡âš¡âš¡ | â­â­â­â­ | $$ | Good alternative |
| llama-3.1-70b | âš¡âš¡âš¡âš¡ | â­â­â­ | $ | Budget option |

## âœ… Hotovo!

NynÃ­ mÃ¡Å¡ plnou kontrolu nad LLM generovÃ¡nÃ­m tÃ©mat:
- âœ… VÃ½bÄ›r modelu
- âœ… NastavenÃ­ temperature
- âœ… Custom instrukce
- âœ… OpenRouter API integrace

StejnÄ› jako u ostatnÃ­ch asistentÅ¯ v aplikaci! ğŸ‰

---

**AktualizovÃ¡no:** Leden 2026  
**Verze:** 1.1  
**Provider:** OpenRouter only



